{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW3uhgDxizGm"
      },
      "source": [
        "## chapter 7장 시계열 분석\n",
        "- 통계 (중급)\n",
        "  + 참조 : https://otexts.com/fppkr/\n",
        "- 페이스북 시계열 예측 라이브러리\n",
        "- 딥러닝 : 일반적인 알고리즘 LSTM \n",
        "- LSTM\n",
        "  + 시계열 & 자연어 처리할 때 도움 줌\n",
        "  + ch10장에서 LSTM을 대체하는 다양한 알고리즘이 이미 나옴. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_WvfrWJki6g"
      },
      "source": [
        "## chapter 8장 성능 최적화\n",
        "- 하이퍼파라미터 튜닝 (교재 p327)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Fro43SxlMFo"
      },
      "source": [
        "## chapter 9장 \n",
        "- p363 \n",
        "- 어간추출 : 영어 동사원형 추출한다. \n",
        "- "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEqoskuYmrY6"
      },
      "source": [
        "## 자연어 처리 라이브러리\n",
        "- NLTK 라이브러리 (https://www.nltk.org/)\n",
        "  + 말뭉치\n",
        "  + 토큰 생성\n",
        "  + 형태소 분석\n",
        "  + 품사 태깅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiTuKXuEiyGR",
        "outputId": "cb2be57c-5d0c-4e52-f998-b79b03b928d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt') #  문장을 단어로 쪼개기 위한 라이브러리\n",
        "string1 = \"my factorite subject is math\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3pfp7Yvn0K1",
        "outputId": "2474501e-542e-43c3-a7c5-ecff83d2cebb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['my', 'factorite', 'subject', 'is', 'math']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.word_tokenize(string1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC6jGYX3oE92"
      },
      "source": [
        "## WSL2 설치 (Ubuntu)\n",
        "- 이번주 금요일 설치\n",
        "- p373 설치 시도"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "e-xbowkuoSsE"
      },
      "outputs": [],
      "source": [
        "# !pip install konlpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHgGoVjYokkZ"
      },
      "source": [
        "## Gensim \n",
        "- 워드투벡터 라이브러리\n",
        "- 단어를 숫자로 바꾸는 것\n",
        "  + CountVectorizer, Tfidf (희소행렬 문제점)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPOtC7DgpFQV"
      },
      "source": [
        "## 결측치 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB2BIF7zpICF",
        "outputId": "a08f4bad-bbec-457d-b0fe-bae8ca62905c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "f3nO9eLMpUV_",
        "outputId": "f18bd86b-4b3f-4e95-dab0-57645802f907"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6, 8)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-016ee9d8-79ce-471e-87a9-c2c7ab937927\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>tissue</th>\n",
              "      <th>class</th>\n",
              "      <th>class2</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>r</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>mdb000</td>\n",
              "      <td>C</td>\n",
              "      <td>CIRC</td>\n",
              "      <td>N</td>\n",
              "      <td>535.0</td>\n",
              "      <td>475.0</td>\n",
              "      <td>192.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>mdb001</td>\n",
              "      <td>A</td>\n",
              "      <td>CIRA</td>\n",
              "      <td>N</td>\n",
              "      <td>433.0</td>\n",
              "      <td>268.0</td>\n",
              "      <td>58.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>mdb002</td>\n",
              "      <td>A</td>\n",
              "      <td>CIRA</td>\n",
              "      <td>I</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>mdb003</td>\n",
              "      <td>C</td>\n",
              "      <td>CIRC</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>mdb004</td>\n",
              "      <td>F</td>\n",
              "      <td>CIRF</td>\n",
              "      <td>I</td>\n",
              "      <td>488.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>29.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>mdb005</td>\n",
              "      <td>F</td>\n",
              "      <td>CIRF</td>\n",
              "      <td>B</td>\n",
              "      <td>544.0</td>\n",
              "      <td>178.0</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-016ee9d8-79ce-471e-87a9-c2c7ab937927')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-016ee9d8-79ce-471e-87a9-c2c7ab937927 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-016ee9d8-79ce-471e-87a9-c2c7ab937927');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0      id tissue class class2      x      y      r\n",
              "0           0  mdb000      C  CIRC      N  535.0  475.0  192.0\n",
              "1           1  mdb001      A  CIRA      N  433.0  268.0   58.0\n",
              "2           2  mdb002      A  CIRA      I    NaN    NaN    NaN\n",
              "3           3  mdb003      C  CIRC      B    NaN    NaN    NaN\n",
              "4           4  mdb004      F  CIRF      I  488.0  145.0   29.0\n",
              "5           5  mdb005      F  CIRF      B  544.0  178.0   26.0"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd \n",
        "DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/산대특/deeplearning/ch09/data/class2.csv'\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print(df.shape)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dccFk3-mpnpQ"
      },
      "source": [
        "- 결측치 처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "oc_GUvImpojd",
        "outputId": "0d995035-7fa6-4d6e-fd41-750087134392"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6, 8)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-48324632-87cc-4f44-8fc4-6ef1649f2c03\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>tissue</th>\n",
              "      <th>class</th>\n",
              "      <th>class2</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>r</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>mdb000</td>\n",
              "      <td>C</td>\n",
              "      <td>CIRC</td>\n",
              "      <td>N</td>\n",
              "      <td>535.0</td>\n",
              "      <td>475.0</td>\n",
              "      <td>192.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>mdb001</td>\n",
              "      <td>A</td>\n",
              "      <td>CIRA</td>\n",
              "      <td>N</td>\n",
              "      <td>433.0</td>\n",
              "      <td>268.0</td>\n",
              "      <td>58.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>mdb002</td>\n",
              "      <td>A</td>\n",
              "      <td>CIRA</td>\n",
              "      <td>I</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>mdb003</td>\n",
              "      <td>C</td>\n",
              "      <td>CIRC</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>mdb004</td>\n",
              "      <td>F</td>\n",
              "      <td>CIRF</td>\n",
              "      <td>I</td>\n",
              "      <td>488.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>29.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>mdb005</td>\n",
              "      <td>F</td>\n",
              "      <td>CIRF</td>\n",
              "      <td>B</td>\n",
              "      <td>544.0</td>\n",
              "      <td>178.0</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48324632-87cc-4f44-8fc4-6ef1649f2c03')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48324632-87cc-4f44-8fc4-6ef1649f2c03 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48324632-87cc-4f44-8fc4-6ef1649f2c03');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0      id tissue class class2      x      y      r\n",
              "0           0  mdb000      C  CIRC      N  535.0  475.0  192.0\n",
              "1           1  mdb001      A  CIRA      N  433.0  268.0   58.0\n",
              "2           2  mdb002      A  CIRA      I    NaN    NaN    NaN\n",
              "3           3  mdb003      C  CIRC      B    NaN    NaN    NaN\n",
              "4           4  mdb004      F  CIRF      I  488.0  145.0   29.0\n",
              "5           5  mdb005      F  CIRF      B  544.0  178.0   26.0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.dropna(how='all') # 모든 행이 NaN 일 때만 삭제\n",
        "print(df.shape)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBtP9i0BtYlB"
      },
      "source": [
        "## 토큰화\n",
        "- 주어진 텍스트를 단어/문자 단위로 자른다. \n",
        "- 영단어는 띄어쓰기가 어느정도 확실함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp1kP-KWt7r6",
        "outputId": "e61eebd8-ee6e-424a-ca9a-7070043f053c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Natural Language Processing, or NLP, is the process of extracting the meaning, or intent, behind human language.', 'In the field of Conversational artificial intelligence (AI), NLP allows machines and applications to understand the intent of human language inputs, and then generate appropriate responses, resulting in a natural conversation flow.']\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "# 문장 토큰화\n",
        "from nltk import sent_tokenize\n",
        "text_sample = 'Natural Language Processing, or NLP, is the process of extracting the meaning, or intent, behind human language. In the field of Conversational artificial intelligence (AI), NLP allows machines and applications to understand the intent of human language inputs, and then generate appropriate responses, resulting in a natural conversation flow.'\n",
        "\n",
        "tokenized_sentences = sent_tokenize(text_sample)\n",
        "print(tokenized_sentences)\n",
        "print(len(tokenized_sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "081lmKEkuT3l",
        "outputId": "41b7fe9c-f7a3-4722-baf0-fdcf89990c88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['This', 'book', 'is', 'for', 'deep', 'learning', 'learners']\n"
          ]
        }
      ],
      "source": [
        "# 단어 토큰화\n",
        "from nltk import word_tokenize \n",
        "sentence = \" This book is for deep learning learners\"\n",
        "words = word_tokenize(sentence)\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-kmz2yEuvbH",
        "outputId": "2af769cf-5fdc-4964-b1cc-4d277eaaddd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['it', '’', 's', 'nothing', 'that', 'you', 'don', '’', 't', 'already', 'know', 'except', 'most', 'people', 'aren', '’', 't', 'aware', 'of', 'how', 'their', 'inner', 'world', 'works', '.']\n"
          ]
        }
      ],
      "source": [
        "# 아포스트로피(') 단어 토큰화\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "sentence = \"it’s nothing that you don’t already know except most people aren’t aware of how their inner world works.\"\n",
        "\n",
        "words = WordPunctTokenizer().tokenize(sentence)\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vdyl0U8vQiJ"
      },
      "source": [
        "- 케라스를 이용한 단어 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHXj4r8vvTYF",
        "outputId": "e1c5492c-2d97-4a88-93ea-cea13b8b0dbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['it’s', 'nothing', 'that', 'you', 'don’t', 'already', 'know', 'except', 'most', 'people', 'aren’t', 'aware', 'of', 'how', 'their', 'inner', 'world', 'works']\n"
          ]
        }
      ],
      "source": [
        "# 아포스트로피(') 단어 토큰화\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "sentence = \"it’s nothing that you don’t already know except most people aren’t aware of how their inner world works.\"\n",
        "\n",
        "words = text_to_word_sequence(sentence)\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPbTh54duumG"
      },
      "source": [
        "## 한글 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-39AHO7vtSH",
        "outputId": "37591e6a-2778-43e1-b89b-0849e1ddde9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.5 MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[K     |████████████████████████████████| 465 kB 64.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "W94SiOSfv7Pm"
      },
      "outputs": [],
      "source": [
        "import csv \n",
        "from konlpy.tag import Okt \n",
        "from gensim.models import word2vec \n",
        "\n",
        "DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/산대특/deeplearning/ch09/data/'\n",
        "f = open(DATA_PATH + r'ratings_train.txt', 'r', encoding='utf-8')\n",
        "rdr = csv.reader(f, delimiter='\\t')\n",
        "rdw = list(rdr) \n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udiIInSwwT02",
        "outputId": "bb296f27-8111-43bb-f16f-d40905d76fe0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['id', 'document', 'label'],\n",
              " ['9976970', '아 더빙.. 진짜 짜증나네요 목소리', '0'],\n",
              " ['3819312', '흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나', '1']]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rdw[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        },
        "id": "Lm_9aNfZxOA-",
        "outputId": "a25960f5-ee14-43ad-b3cb-9e9656877546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "document\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-14-a682c2a93152>\", line 5, in <module>\n",
            "    malist = twitter.pos( line[1], norm=True, stem=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/konlpy/tag/_okt.py\", line 74, in pos\n",
            "    jpype.java.lang.Boolean(stem)).toArray()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 742, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 395, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
            "    if not islink(newpath):\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 171, in islink\n",
            "    st = os.lstat(path)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ],
      "source": [
        "twitter = Okt()\n",
        "\n",
        "result = []\n",
        "for line in rdw:\n",
        "    malist = twitter.pos( line[1], norm=True, stem=True)\n",
        "    r = []\n",
        "    for word in malist:\n",
        "        if not word[1] in [\"Josa\",\"Eomi\",\"Punctuation\"]:\n",
        "            r.append(word[0])\n",
        "    rl = (\" \".join(r)).strip()\n",
        "    result.append(rl)\n",
        "    print(rl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDiy6A6HxYu8"
      },
      "source": [
        "- 형태소 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NUKAuwHyeop",
        "outputId": "10574a17-ae04-4ee7-8a18-738ca7490957"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xNVpNpmylPv",
        "outputId": "ad400c8d-7b1c-4d6c-d03d-bd2eac25dc65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/산대특/deeplearning/ch09/data\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/산대특/deeplearning/ch09/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH5Mi7fJyuDY",
        "outputId": "d6c292f1-f22a-46a3-af05-dfbc75076008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "class2.csv     covtype.csv     ratings_test.txt\n",
            "covertype.csv  NaverMovie.nlp  ratings_train.txt\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0g4ok8o8xaSQ"
      },
      "outputs": [],
      "source": [
        "with open(\"NaverMovie.nlp\", 'w', encoding='utf-8') as fp:\n",
        "  fp.write(\"\\n\".join(result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR84vuFXzTZd"
      },
      "source": [
        "## Word2Vec 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "dAW9UDkTzVjD",
        "outputId": "94f6fdd3-63fd-4ccf-ae31-7163523c1679"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-ce8b51fa47a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLineSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NaverMovie.nlp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NaverMovie.model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, max_final_vocab)\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbow_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbow_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m             fast_version=FAST_VERSION)\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     def _do_train_epoch(self, corpus_file, thread_id, offset, cython_vocab, thread_private_mem, cur_epoch,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, workers, vector_size, epochs, callbacks, batch_words, trim_rule, sg, alpha, window, seed, hs, negative, ns_exponent, cbow_mean, min_alpha, compute_loss, fast_version, **kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m                 \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m                 \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                 end_alpha=self.min_alpha, compute_loss=compute_loss)\n\u001b[0m\u001b[1;32m    764\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrim_rule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks)\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m             queue_factor=queue_factor, report_delay=report_delay, compute_loss=compute_loss, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_sentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_job_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             total_words=total_words, **kwargs)\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_check_training_sanity\u001b[0;34m(self, epochs, total_examples, total_words, **kwargs)\u001b[0m\n\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# should be set by `build_vocab`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"you must first build vocabulary before training the model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"you must initialize vectors before training the model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: you must first build vocabulary before training the model"
          ]
        }
      ],
      "source": [
        "mData = word2vec.LineSentence(\"NaverMovie.nlp\")\n",
        "mModel = word2vec.Word2Vec(mData, size = 200, window=10, hs=1, min_count=2, sg=1)\n",
        "mModel.save(\"NaverMovie.model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJ47oJ6qzz9R"
      },
      "source": [
        "## 불용어 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfxzxMioz12g",
        "outputId": "bea08d6b-8311-4b1b-d1b4-4e29bbc1d690"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "불용어 제거 미적용: ['One', 'of', 'the', 'first', 'things', 'that', 'we', 'ask', 'ourselves', 'is', 'what', 'are', 'the', 'pros', 'and', 'cons', 'of', 'any', 'task', 'we', 'perform', '.'] \n",
            "\n",
            "불용어 제거 적용: ['One', 'first', 'things', 'ask', 'pros', 'cons', 'task', 'perform', '.']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords \n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "sample_text = \"One of the first things that we ask ourselves is what are the pros and cons of any task we perform.\"\n",
        "text_tokens = word_tokenize(sample_text)\n",
        "\n",
        "tokens_without_sw = [word for word in text_tokens if not word in stopwords.words('english')]\n",
        "print(\"불용어 제거 미적용:\", text_tokens, '\\n')\n",
        "print(\"불용어 제거 적용:\",tokens_without_sw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlheOibh0mR3"
      },
      "source": [
        "## 어간 추출\n",
        "- 단어의 원형을 찾아준다. \n",
        "- NLTK : 포터(porter) & 랭커스터(lancaster) 알고리즘\n",
        "- 표제어 추출 : 어간 추출보다 성능이 더 좋음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulRVrxon1hOA",
        "outputId": "d0e86ffe-9f22-44f5-cd9a-db2f7239ab7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "obess obsses\n",
            "standard standard\n",
            "nation nation\n",
            "absent absent\n",
            "tribal tribalic\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# 포터 알고리즘\n",
        "print(stemmer.stem('obesses'),stemmer.stem('obssesed'))\n",
        "print(stemmer.stem('standardizes'),stemmer.stem('standardization'))\n",
        "print(stemmer.stem('national'), stemmer.stem('nation'))\n",
        "print(stemmer.stem('absentness'), stemmer.stem('absently'))\n",
        "print(stemmer.stem('tribalical'), stemmer.stem('tribalicalized'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g20SwqGY1ofQ",
        "outputId": "45d43513-93a4-4ea5-98b1-6e522fa6ffc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "obsess obsess\n",
            "standard standard\n",
            "nat nat\n",
            "abs abs\n",
            "trib trib\n"
          ]
        }
      ],
      "source": [
        "# 랭커스터 알고리즘\n",
        "from nltk.stem import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "\n",
        "print(stemmer.stem('obsesses'),stemmer.stem('obsessed'))\n",
        "print(stemmer.stem('standardizes'),stemmer.stem('standardization'))\n",
        "print(stemmer.stem('national'), stemmer.stem('nation'))\n",
        "print(stemmer.stem('absentness'), stemmer.stem('absently'))\n",
        "print(stemmer.stem('tribalical'), stemmer.stem('tribalicalized'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKZBqABH1slP",
        "outputId": "572e700c-651c-4f66-c3db-bcace117941a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "obsess obsess\n",
            "standardizes standardization\n",
            "national nation\n",
            "absentness absently\n",
            "tribalical tribalicalized\n"
          ]
        }
      ],
      "source": [
        "# 표제어 추출\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4') # 추가해주세요! \n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemma = WordNetLemmatizer()\n",
        "\n",
        "print(stemmer.stem('obsesses'),stemmer.stem('obsessed'))\n",
        "print(lemma.lemmatize('standardizes'),lemma.lemmatize('standardization'))\n",
        "print(lemma.lemmatize('national'), lemma.lemmatize('nation'))\n",
        "print(lemma.lemmatize('absentness'), lemma.lemmatize('absently'))\n",
        "print(lemma.lemmatize('tribalical'), lemma.lemmatize('tribalicalized'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8gziNrX20ee"
      },
      "source": [
        "## 정규화\n",
        "- covtype.csv 파일 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9c3AXsP3Dde",
        "outputId": "6a3bf228-3bbb-41c3-8b7e-6b3f8f1ea33f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "class2.csv     covtype.csv     ratings_test.txt\n",
            "covertype.csv  NaverMovie.nlp  ratings_train.txt\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfbNEMCS2e_o",
        "outputId": "dd11307a-888c-4a08-ccd7-f2fbc759ed6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-11-01 02:19:34--  https://github.com/gilbutITbook/080263/releases/download/0.1/covtype.csv\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/344368063/859a0b00-7cfc-11eb-8f61-b2e8d5afeb8d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221101T021934Z&X-Amz-Expires=300&X-Amz-Signature=761cca81f9dbb1a6ed5f31922b2050e69f5f8f3fe86246b8c91a222e16890f18&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=344368063&response-content-disposition=attachment%3B%20filename%3Dcovtype.csv&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-11-01 02:19:34--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/344368063/859a0b00-7cfc-11eb-8f61-b2e8d5afeb8d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221101T021934Z&X-Amz-Expires=300&X-Amz-Signature=761cca81f9dbb1a6ed5f31922b2050e69f5f8f3fe86246b8c91a222e16890f18&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=344368063&response-content-disposition=attachment%3B%20filename%3Dcovtype.csv&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75170064 (72M) [application/octet-stream]\n",
            "Saving to: ‘covtype.csv.1’\n",
            "\n",
            "covtype.csv.1       100%[===================>]  71.69M   102MB/s    in 0.7s    \n",
            "\n",
            "2022-11-01 02:19:35 (102 MB/s) - ‘covtype.csv.1’ saved [75170064/75170064]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# !wget https://github.com/gilbutITbook/080263/releases/download/0.1/covtype.csv\n",
        "!wget https://datahub.io/machine-learning/covertype/r/covertype.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE40EOOa7Asp"
      },
      "source": [
        "## 정규화 유무 모델링 결과 비교\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFsppgHz7Y0q",
        "outputId": "2aabc520-23f5-4614-e866-875172dbcb8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "class2.csv     covtype.csv    NaverMovie.nlp\tratings_train.txt\n",
            "covertype.csv  covtype.csv.1  ratings_test.txt\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "CkmtoTv_7IFJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# 교재 389\n",
        "df = pd.read_csv(\"covertype.csv\")\n",
        "x = df[df.columns[:54]]\n",
        "# y = df.Cover_Type (with covtype.csv)\n",
        "y = df['class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyalu_YH-qzg",
        "outputId": "8ef0a81e-052e-480f-fe0a-2672213f58ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2    283301\n",
              "1    211840\n",
              "3     35754\n",
              "7     20510\n",
              "6     17367\n",
              "5      9493\n",
              "4      2747\n",
              "Name: Cover_Type, dtype: int64"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.Cover_Type.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS2Xu10eEcV4",
        "outputId": "e0b4f196-e58b-4573-e03e-833292d9656d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2    283301\n",
              "1    211840\n",
              "3     35754\n",
              "7     20510\n",
              "6     17367\n",
              "5      9493\n",
              "4      2747\n",
              "Name: class, dtype: int64"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQb_0B9G76Xl",
        "outputId": "789877b3-a45d-4512-8985-1c97230e2fba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((581012, 54), (581012,))"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6PPb-d58Wt0"
      },
      "source": [
        "- 데이터셋 분리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI8BgkHj8ELb",
        "outputId": "c8f34a7f-f0e3-4286-aaca-4fdbbc49d700"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((406708, 54), (174304, 54), (406708,), (174304,))"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x, y, train_size = 0.7, random_state=90\n",
        ")\n",
        "\n",
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yKoUDeD8y6F",
        "outputId": "305f95cb-d7a7-4e76-f407-26cea60f919a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cEtXtRP8ZeA"
      },
      "source": [
        "- 모델 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qRCMwnE8V6k",
        "outputId": "758250a8-a420-4a87-a6b3-6e416246ad84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/26\n",
            "6779/6779 [==============================] - 22s 3ms/step - loss: 0.6403 - accuracy: 0.7261 - val_loss: 0.5747 - val_accuracy: 0.7511\n",
            "Epoch 2/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 0.5562 - accuracy: 0.7588 - val_loss: 0.5473 - val_accuracy: 0.7642\n",
            "Epoch 3/26\n",
            "6779/6779 [==============================] - 28s 4ms/step - loss: 0.5204 - accuracy: 0.7735 - val_loss: 0.5067 - val_accuracy: 0.7769\n",
            "Epoch 4/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 0.4940 - accuracy: 0.7856 - val_loss: 0.4935 - val_accuracy: 0.7842\n",
            "Epoch 5/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 0.4746 - accuracy: 0.7956 - val_loss: 0.4636 - val_accuracy: 0.8011\n",
            "Epoch 6/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 0.4572 - accuracy: 0.8039 - val_loss: 0.4632 - val_accuracy: 0.8010\n",
            "Epoch 7/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 0.4433 - accuracy: 0.8107 - val_loss: 0.4396 - val_accuracy: 0.8107\n",
            "Epoch 8/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 0.4313 - accuracy: 0.8166 - val_loss: 0.4363 - val_accuracy: 0.8139\n",
            "Epoch 9/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 0.4212 - accuracy: 0.8218 - val_loss: 0.4308 - val_accuracy: 0.8158\n",
            "Epoch 10/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 0.4126 - accuracy: 0.8262 - val_loss: 0.4063 - val_accuracy: 0.8300\n",
            "Epoch 11/26\n",
            "6779/6779 [==============================] - 22s 3ms/step - loss: 0.4044 - accuracy: 0.8296 - val_loss: 0.3983 - val_accuracy: 0.8323\n",
            "Epoch 12/26\n",
            "6779/6779 [==============================] - 22s 3ms/step - loss: 0.3980 - accuracy: 0.8325 - val_loss: 0.4030 - val_accuracy: 0.8275\n",
            "Epoch 13/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 0.3918 - accuracy: 0.8349 - val_loss: 0.4146 - val_accuracy: 0.8276\n",
            "Epoch 14/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 0.3865 - accuracy: 0.8382 - val_loss: 0.3834 - val_accuracy: 0.8406\n",
            "Epoch 15/26\n",
            "6779/6779 [==============================] - 22s 3ms/step - loss: 0.3819 - accuracy: 0.8392 - val_loss: 0.3827 - val_accuracy: 0.8402\n",
            "Epoch 16/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 0.3773 - accuracy: 0.8422 - val_loss: 0.3783 - val_accuracy: 0.8410\n",
            "Epoch 17/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 0.3736 - accuracy: 0.8438 - val_loss: 0.3628 - val_accuracy: 0.8512\n",
            "Epoch 18/26\n",
            "6779/6779 [==============================] - 23s 3ms/step - loss: 0.3692 - accuracy: 0.8459 - val_loss: 0.3686 - val_accuracy: 0.8463\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, \n",
        "                          activation='relu', \n",
        "                          input_shape=(x_train.shape[1], )),\n",
        "    tf.keras.layers.Dense(64, activation='relu'), \n",
        "    tf.keras.layers.Dense(8, activation='softmax') \n",
        "])\n",
        "\n",
        "model.compile(optimizer= tf.keras.optimizers.Adam(0.001),\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "history1 = model.fit(\n",
        " x_train, y_train, epochs= 26, batch_size = 60, validation_data = (x_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqnJ-D5Y9yR5"
      },
      "source": [
        "- 데이터 정규화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lm9qhYO_911s",
        "outputId": "b69bea64-c4ae-4316-9787-a94d652800be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Elevation    Aspect     Slope  Horizontal_Distance_To_Hydrology  \\\n",
            "152044   0.222366 -0.228639 -0.412503                          0.148486   \n",
            "363373   1.980490 -0.469989  0.255453                          3.018822   \n",
            "372733  -1.081933  0.271939  0.389044                         -0.867895   \n",
            "572846  -1.164122 -0.157128 -0.278912                         -1.267860   \n",
            "114145  -0.052787  0.861906  0.255453                         -0.279711   \n",
            "\n",
            "        Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
            "152044                        0.149095                         1.336119   \n",
            "363373                        4.443372                         0.168073   \n",
            "372733                       -0.160093                        -0.241801   \n",
            "572846                       -0.795646                        -0.461170   \n",
            "114145                       -0.125739                         1.811419   \n",
            "\n",
            "        Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
            "152044       1.002687        0.539776      -0.510339   \n",
            "363373       1.227001       -0.270132      -1.190275   \n",
            "372733       0.292357        1.349684       0.378807   \n",
            "572846       0.965301        0.641014      -0.431885   \n",
            "114145      -1.090917        1.299065       1.581770   \n",
            "\n",
            "        Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
            "152044                           -0.111226  ...            0            0   \n",
            "363373                           -0.703030  ...            0            0   \n",
            "372733                            0.038235  ...            0            0   \n",
            "572846                           -1.450334  ...            0            0   \n",
            "114145                           -0.328623  ...            0            0   \n",
            "\n",
            "        Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
            "152044            0            0            0            0            0   \n",
            "363373            0            0            0            0            0   \n",
            "372733            0            0            0            0            0   \n",
            "572846            0            0            0            0            0   \n",
            "114145            0            0            0            0            0   \n",
            "\n",
            "        Soil_Type39  Soil_Type40  Cover_Type  \n",
            "152044            0            0           2  \n",
            "363373            0            1           1  \n",
            "372733            0            0           3  \n",
            "572846            0            0           2  \n",
            "114145            0            0           2  \n",
            "\n",
            "[5 rows x 55 columns]\n"
          ]
        }
      ],
      "source": [
        "# p390\n",
        "from sklearn import preprocessing \n",
        "df = pd.read_csv(\"covtype.csv\")\n",
        "x = df[df.columns[:55]]\n",
        "y = df.Cover_Type\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.7, random_state=90)\n",
        "\n",
        "# 중요 포인트 \n",
        "train_norm = x_train[x_train.columns[0:10]] # 훈련 10개의 컬럼 선택\n",
        "test_norm = x_test[x_test.columns[0:10]] # 테스트 10개의 컬럼 선택\n",
        "\n",
        "std_scale = preprocessing.StandardScaler().fit(train_norm) \n",
        "x_train_norm = std_scale.transform(train_norm)\n",
        "\n",
        "traininig_norm_col = pd.DataFrame(x_train_norm, \n",
        "                                  index=train_norm.index, \n",
        "                                  columns = train_norm.columns)\n",
        "x_train.update(traininig_norm_col)\n",
        "print(x_train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YVwQDCqA5fQ",
        "outputId": "414b7e9c-a17a-45db-a9c2-68714a80d22c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Elevation    Aspect     Slope  Horizontal_Distance_To_Hydrology  \\\n",
            "204886   0.783394 -1.310245 -0.946867                          0.233185   \n",
            "116027  -0.903262 -1.006323 -0.679685                         -1.267860   \n",
            "328145  -0.270766 -1.095711 -0.278912                          0.379054   \n",
            "579670  -1.139108 -0.961628 -0.412503                          0.454342   \n",
            "41341    0.265247  0.736762 -1.347641                          2.708261   \n",
            "\n",
            "        Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
            "204886                       -1.465554                         0.093026   \n",
            "116027                       -0.795646                        -0.611906   \n",
            "328145                        0.200626                        -0.948657   \n",
            "579670                        0.389574                        -0.772905   \n",
            "41341                         2.072931                         2.321998   \n",
            "\n",
            "        Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
            "204886      -0.006729        0.084203       0.221899   \n",
            "116027       0.367128       -0.168893      -0.274977   \n",
            "328145       0.217585       -0.472609      -0.301128   \n",
            "579670       0.441900       -0.421989      -0.510339   \n",
            "41341       -0.006729        1.045968       0.718775   \n",
            "\n",
            "        Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
            "204886                            0.253368  ...            0            0   \n",
            "116027                            0.226194  ...            0            0   \n",
            "328145                           -0.330133  ...            0            0   \n",
            "579670                           -0.882685  ...            0            0   \n",
            "41341                             1.243735  ...            0            0   \n",
            "\n",
            "        Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
            "204886            0            0            0            0            0   \n",
            "116027            0            0            0            0            0   \n",
            "328145            0            0            0            0            0   \n",
            "579670            0            0            0            0            0   \n",
            "41341             0            0            0            0            0   \n",
            "\n",
            "        Soil_Type39  Soil_Type40  Cover_Type  \n",
            "204886            0            0           1  \n",
            "116027            0            0           2  \n",
            "328145            0            0           2  \n",
            "579670            0            0           3  \n",
            "41341             0            0           2  \n",
            "\n",
            "[5 rows x 55 columns]\n"
          ]
        }
      ],
      "source": [
        "x_test_norm = std_scale.transform(test_norm) # 테스트 데이터셋 정규화 \n",
        "testing_norm_col = pd.DataFrame(x_test_norm, \n",
        "                                index = test_norm.index, \n",
        "                                columns = test_norm.columns)\n",
        "\n",
        "x_test.update(testing_norm_col)\n",
        "print(x_test.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IepHjWl9Bcdv",
        "outputId": "b024318a-0611-40c1-a658-dc77fc2decc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/26\n",
            "6779/6779 [==============================] - 25s 4ms/step - loss: 0.0289 - accuracy: 0.9921 - val_loss: 1.1251e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/26\n",
            "6779/6779 [==============================] - 22s 3ms/step - loss: 2.2766e-04 - accuracy: 0.9999 - val_loss: 1.7412e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/26\n",
            "6779/6779 [==============================] - 22s 3ms/step - loss: 3.2007e-04 - accuracy: 0.9999 - val_loss: 3.7853e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/26\n",
            "6779/6779 [==============================] - 22s 3ms/step - loss: 2.7720e-04 - accuracy: 0.9999 - val_loss: 6.6570e-06 - val_accuracy: 1.0000\n",
            "Epoch 5/26\n",
            "6779/6779 [==============================] - 23s 3ms/step - loss: 1.8362e-04 - accuracy: 1.0000 - val_loss: 1.9625e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 1.0155e-04 - accuracy: 1.0000 - val_loss: 6.9932e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 2.7590e-04 - accuracy: 0.9999 - val_loss: 1.3735e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/26\n",
            "6779/6779 [==============================] - 22s 3ms/step - loss: 1.8330e-04 - accuracy: 1.0000 - val_loss: 1.3152e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 2.0110e-04 - accuracy: 1.0000 - val_loss: 7.2673e-07 - val_accuracy: 1.0000\n",
            "Epoch 10/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 3.3133e-07 - accuracy: 1.0000 - val_loss: 1.1805e-07 - val_accuracy: 1.0000\n",
            "Epoch 11/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 1.6840e-04 - accuracy: 1.0000 - val_loss: 2.6635e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/26\n",
            "6779/6779 [==============================] - 22s 3ms/step - loss: 2.5879e-07 - accuracy: 1.0000 - val_loss: 3.8853e-07 - val_accuracy: 1.0000\n",
            "Epoch 13/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 2.4323e-08 - accuracy: 1.0000 - val_loss: 1.6242e-08 - val_accuracy: 1.0000\n",
            "Epoch 14/26\n",
            "6779/6779 [==============================] - 22s 3ms/step - loss: 2.6379e-04 - accuracy: 0.9999 - val_loss: 1.3169e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 1.2808e-04 - accuracy: 1.0000 - val_loss: 1.1497e-07 - val_accuracy: 1.0000\n",
            "Epoch 16/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 1.9531e-04 - accuracy: 1.0000 - val_loss: 2.0200e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 8.9486e-08 - accuracy: 1.0000 - val_loss: 2.2010e-08 - val_accuracy: 1.0000\n",
            "Epoch 18/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 1.0442e-08 - accuracy: 1.0000 - val_loss: 1.0087e-08 - val_accuracy: 1.0000\n",
            "Epoch 19/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 1.2345e-04 - accuracy: 1.0000 - val_loss: 5.1267e-08 - val_accuracy: 1.0000\n",
            "Epoch 20/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 1.1594e-08 - accuracy: 1.0000 - val_loss: 5.0855e-09 - val_accuracy: 1.0000\n",
            "Epoch 21/26\n",
            "6779/6779 [==============================] - 22s 3ms/step - loss: 1.1900e-09 - accuracy: 1.0000 - val_loss: 4.9019e-08 - val_accuracy: 1.0000\n",
            "Epoch 22/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 3.4075e-04 - accuracy: 0.9999 - val_loss: 5.1974e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/26\n",
            "6779/6779 [==============================] - 22s 3ms/step - loss: 1.5825e-04 - accuracy: 1.0000 - val_loss: 2.8155e-04 - val_accuracy: 0.9999\n",
            "Epoch 24/26\n",
            "6779/6779 [==============================] - 21s 3ms/step - loss: 3.3372e-07 - accuracy: 1.0000 - val_loss: 6.2638e-08 - val_accuracy: 1.0000\n",
            "Epoch 25/26\n",
            "6779/6779 [==============================] - 22s 3ms/step - loss: 6.7526e-09 - accuracy: 1.0000 - val_loss: 1.8021e-09 - val_accuracy: 1.0000\n",
            "Epoch 26/26\n",
            "6779/6779 [==============================] - 22s 3ms/step - loss: 4.8216e-10 - accuracy: 1.0000 - val_loss: 2.2159e-10 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        " tf.keras.layers.Dense(64, activation='relu',                  \n",
        " input_shape=(x_train.shape[1],)),\n",
        " tf.keras.layers.Dense(64, activation='relu'),\n",
        " tf.keras.layers.Dense(8, activation=  'softmax')\n",
        " ])\n",
        "\n",
        "model.compile(optimizer= tf.keras.optimizers.Adam(0.001),\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "history2 = model.fit(\n",
        " x_train, y_train,\n",
        " epochs= 26, batch_size = 60,\n",
        " validation_data = (x_test, y_test))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
